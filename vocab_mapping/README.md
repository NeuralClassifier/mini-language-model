# mini-language-model

Given a text dataset $D$, we define a tokenization function $\phi: D \to T^*$, where