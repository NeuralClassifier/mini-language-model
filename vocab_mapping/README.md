# Vocabulary Mapping

Given a text dataset $D$, we define a tokenization function $\phi: D \to T^x$, where:

$$
T^x = \{t_i \mid i \leq n\}
$$

The Vocabulary Mapping function can be written as:

$$
\mu : T \to {0, 1, \ldots n-1}
$$